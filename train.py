import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import os
import numpy as np
import cv2
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# --- 1. FFT è™•ç†å‡½å¼ ---
def get_fft_spectrum(img_pil):
    """æå–åœ–ç‰‡çš„ FFT é »è­œç‰¹å¾µä¸¦è½‰ç‚º Tensor"""
    # è½‰ç°éšä¸¦è½‰ç‚º numpy
    img_gray = np.array(img_pil.convert('L'))
    # åŸ·è¡Œ FFT
    f = np.fft.fft2(img_gray)
    fshift = np.fft.fftshift(f)
    # å–æŒ¯å¹…è­œä¸¦é€²è¡Œå°æ•¸è®Šæ›
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1)
    # æ¨™æº–åŒ–åˆ° 0-1
    magnitude_spectrum = cv2.normalize(magnitude_spectrum, None, 0, 1, cv2.NORM_MINMAX)
    # è½‰å› Tensor ä¸¦èª¿æ•´å°ºå¯¸
    fft_tensor = torch.from_numpy(magnitude_spectrum).float().unsqueeze(0) # [1, H, W]
    return fft_tensor

# --- 2. è‡ªå®šç¾© Dataset (é›™æµç‰ˆ) ---
class RVFDatasetFFT(Dataset):
    def __init__(self, csv_file, root_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.root_dir = root_dir
        self.transform = transform
        self.to_tensor = transforms.ToTensor()

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_rel_path = str(self.data.loc[idx, 'path'])
        img_path = os.path.join(self.root_dir, img_rel_path)
        label = int(self.data.loc[idx, 'label'])

        # 1. è®€åœ–
        image_pil = Image.open(img_path).convert("RGB")

        # 2. å…ˆ Resizeï¼ˆé—œéµï¼‰
        image_pil = transforms.Resize((224, 224))(image_pil)

        # 3. FFTï¼ˆå¾ resize å¾Œã€æœª normalize çš„åœ–ï¼‰
        fft_feature = get_fft_spectrum(image_pil)   # [1,224,224]

        # 4. RGB transformï¼ˆToTensor + Normalizeï¼‰
        if self.transform:
            image = self.transform(image_pil)       # [3,224,224]
        else:
            image = transforms.ToTensor()(image_pil)

        # 5. æ‹¼æ¥ RGB + FFT
        combined_input = torch.cat((image, fft_feature), dim=0)  # [4,224,224]

        return combined_input, label


# --- 3. è¨­å®šèˆ‡æº–å‚™ ---
DATA_ROOT = "./rvf10k"
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 32

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.2, 0.2, 0.2),
    transforms.GaussianBlur(3, sigma=(0.1, 2.0)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

valid_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_loader = DataLoader(RVFDatasetFFT(os.path.join(DATA_ROOT, "train.csv"), DATA_ROOT, train_transform), batch_size=BATCH_SIZE, shuffle=True)
valid_loader = DataLoader(RVFDatasetFFT(os.path.join(DATA_ROOT, "valid.csv"), DATA_ROOT, valid_transform), batch_size=BATCH_SIZE)

# --- 4. ä¿®æ”¹æ¨¡å‹ä»¥æ¥æ”¶ 4 é€šé“ (RGB + FFT) ---
model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
# ä¿®æ”¹ç¬¬ä¸€å±¤å·ç©
old_conv = model.conv1
model.conv1 = nn.Conv2d(4, old_conv.out_channels, kernel_size=old_conv.kernel_size, 
                        stride=old_conv.stride, padding=old_conv.padding, bias=False)
# å°‡åŸæœ‰çš„æ¬Šé‡è¤‡è£½çµ¦å‰ 3 å€‹é€šé“ï¼Œç¬¬ 4 é€šé“åˆå§‹åŒ–
with torch.no_grad():
    model.conv1.weight[:, :3, :, :] = old_conv.weight
    model.conv1.weight[:, 3, :, :] = torch.mean(old_conv.weight, dim=1)

model.fc = nn.Linear(model.fc.in_features, 2)
model = model.to(DEVICE)

optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
criterion = nn.CrossEntropyLoss()

# --- 5. è¨“ç·´è¿´åœˆ (åŒå‰ï¼Œç•¥ç¸®) ---
EPOCHS = 1
print(f"ğŸš€ é–‹å§‹ FFT+RGB é›™æµè¨“ç·´...")
print(f"ğŸš€ è¨“ç·´è¨­å‚™: {DEVICE}")
print(f"ğŸš€ è¨“ç·´æ¨£æœ¬æ•¸: {len(train_loader.dataset)}")
print(f"ğŸš€ é©—è­‰æ¨£æœ¬æ•¸: {len(valid_loader.dataset)}")
print(f"ğŸš€ æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
print(f"ğŸš€ ç¸½è¨“ç·´è¼ªæ•¸: {EPOCHS}")

for epoch in range(EPOCHS):
    model.train()
    pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}")
    for imgs, lbls in pbar:
        imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)
        optimizer.zero_grad()
        loss = criterion(model(imgs), lbls)
        loss.backward()
        optimizer.step()
        pbar.set_postfix({"loss": f"{loss.item():.4f}"})

# --- 6. æœ€çµ‚è©•ä¼° (Classification Report & Confusion Matrix) ---

print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆæœ€çµ‚è©•ä¼°å ±å‘Š...")
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in tqdm(valid_loader, desc="Validating"):
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# å°å‡º Classification Report
# æ ¹æ“šä½ çš„ CSV: 0 æ˜¯ Fake, 1 æ˜¯ Real
target_names = ['Fake (0)', 'Real (1)']
print("\n\nğŸ“ Classification Report:")
print(classification_report(all_labels, all_preds, target_names=target_names))

# ç¹ªè£½ Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
print("\n\næ··æ·†çŸ©é™£:")
print(cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.savefig('confusion_matrix.png')
print("âœ… æ··æ·†çŸ©é™£å·²å„²å­˜ç‚º confusion_matrix.png")

torch.save(model.state_dict(), "rvf10k_model.pth")
print("âœ… æ¨¡å‹å·²å„²å­˜ã€‚")