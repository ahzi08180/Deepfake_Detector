import streamlit as st
import torch
import torch.nn as nn
import timm
from PIL import Image
from facenet_pytorch import MTCNN
import torchvision.transforms as transforms

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="Deepfake åœ–ç‰‡åµæ¸¬å™¨", layout="centered")
st.title("ğŸ›¡ï¸ Deepfake åœ–ç‰‡åµæ¸¬ç³»çµ±")
st.write("ä¸Šå‚³ä¸€å¼µäººè‡‰ç…§ç‰‡ï¼Œç³»çµ±å°‡åˆ†æå…¶æ˜¯å¦ç‚º AI ç”Ÿæˆã€‚")

# --- 1. å®šç¾©æ¨¡å‹æ¶æ§‹ ---
class DeepfakeDetector(nn.Module):
    def __init__(self):
        super(DeepfakeDetector, self).__init__()
        # ä½¿ç”¨é«˜æ•ˆçš„ EfficientNet-B0
        self.backbone = timm.create_model('efficientnet_b0', pretrained=True)
        num_ftrs = self.backbone.classifier.in_features
        self.backbone.classifier = nn.Sequential(
            nn.Linear(num_ftrs, 1) # è¼¸å‡ºå–®ä¸€æ•¸å€¼ï¼Œç”¨æ–¼äºŒåˆ†é¡
        )

    def forward(self, x):
        return torch.sigmoid(self.backbone(x))

# --- 2. è¼‰å…¥æ¨¡å‹èˆ‡å·¥å…· ---
@st.cache_resource
def load_tools():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # äººè‡‰åµæ¸¬å™¨
    mtcnn = MTCNN(image_size=224, margin=20, device=device)
    # é æ¸¬æ¨¡å‹
    model = DeepfakeDetector().to(device)
    model.eval()
    return mtcnn, model, device

mtcnn, model, device = load_tools()

# å½±åƒé è™•ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# --- 3. ç¶²é ä»‹é¢å¯¦ä½œ ---
uploaded_file = st.file_uploader("é¸æ“‡ä¸€å¼µåœ–ç‰‡...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert('RGB')
    st.image(image, caption='åŸå§‹åœ–ç‰‡', use_column_width=True)
    
    with st.spinner('æ­£åœ¨åˆ†æä¸­...'):
        # æ­¥é©Ÿ A: åµæ¸¬äººè‡‰
        face = mtcnn(image)
        
        if face is not None:
            # æ­¥é©Ÿ B: é è™•ç†ä¸¦é æ¸¬
            # MTCNN è¼¸å‡ºçš„ face å·²ç¶“æ˜¯ Tensor
            face_input = face.unsqueeze(0).to(device)
            
            with torch.no_grad():
                output = model(face_input).item()
            
            # é¡¯ç¤ºçµæœ (å‡è¨­ > 0.5 ç‚º Fake)
            st.divider()
            if output > 0.5:
                st.error(f"åˆ¤å®šçµæœï¼šğŸš¨ ç–‘ä¼¼ç‚º Deepfake å½é€ åœ–ç‰‡")
                st.progress(output)
                st.write(f"å½é€ å¯èƒ½æ€§: {output*100:.2f}%")
            else:
                st.success(f"åˆ¤å®šçµæœï¼šâœ… é€™çœ‹èµ·ä¾†åƒæ˜¯ çœŸå¯¦ç…§ç‰‡")
                st.progress(output)
                st.write(f"çœŸå¯¦å¯èƒ½æ€§: {(1-output)*100:.2f}%")
                
            # é¡¯ç¤ºæ¨¡å‹çœ‹åˆ°çš„äººè‡‰éƒ¨åˆ†
            st.image(face.permute(1, 2, 0).numpy() / 2 + 0.5, caption="åµæ¸¬åˆ°çš„äººè‡‰å€åŸŸ", width=150)
        else:
            st.warning("ç„¡æ³•åœ¨åœ–ç‰‡ä¸­åµæ¸¬åˆ°æ¸…æ™°çš„äººè‡‰ï¼Œè«‹æ›ä¸€å¼µè©¦è©¦çœ‹ã€‚")

st.info("è¨»ï¼šæ­¤æ¨¡å‹ç›®å‰ä½¿ç”¨åŸºç¤é è¨“ç·´æ¬Šé‡ï¼Œè‹¥è¦é”åˆ°å•†ç”¨ç²¾æº–åº¦ï¼Œéœ€è¼‰å…¥é‡å° DFDC è³‡æ–™é›†è¨“ç·´å¾Œçš„ .pth æ¬Šé‡æª”æ¡ˆã€‚")