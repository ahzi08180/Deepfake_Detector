import streamlit as st
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
from facenet_pytorch import MTCNN
import numpy as np
import cv2
import os

st.set_page_config(page_title="FFT Deepfake Detector", layout="wide")
st.title("ğŸ›¡ï¸ é »åŸŸåˆ†æ Deepfake åµæ¸¬ç³»çµ± (FFT + RGB)")

@st.cache_resource
def load_all():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    mtcnn = MTCNN(image_size=224, margin=20, device=device)
    
    # åˆå§‹åŒ– 4 é€šé“ ResNet18
    model = models.resnet18(weights=None)
    model.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)
    model.fc = nn.Linear(model.fc.in_features, 2)
    
    model_path = "rvf10k_fft_model.pth"
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
    
    model.to(device).eval()
    return mtcnn, model, device

mtcnn, model, device = load_all()

def process_fft(face_pil):
    # 1. è½‰ç°éšä¸¦è½‰ç‚º numpy
    img_gray = np.array(face_pil.convert('L'))
    # 2. åŸ·è¡Œ 2D FFT
    f = np.fft.fft2(img_gray)
    fshift = np.fft.fftshift(f)
    # 3. è¨ˆç®—æŒ¯å¹…è­œä¸¦åšå°æ•¸è®Šæ›
    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1)
    
    # 4. æ­£è¦åŒ–åˆ° 0.0 - 1.0 (float32)
    magnitude_spectrum = cv2.normalize(magnitude_spectrum, None, 0.0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)
    
    # 5. å¼·åˆ¶é™åˆ¶ç¯„åœåœ¨ [0.0, 1.0]ï¼Œé¿å…æµ®é»æ•¸æº¢å‡ºå°è‡´ Streamlit å ±éŒ¯
    magnitude_spectrum = np.clip(magnitude_spectrum, 0.0, 1.0)
    
    return torch.from_numpy(magnitude_spectrum).float().unsqueeze(0)

uploaded_file = st.file_uploader("ä¸Šå‚³ç…§ç‰‡é€²è¡Œé »åŸŸåˆ†æ...", type=["jpg", "png", "jpeg"])

if uploaded_file:
    img = Image.open(uploaded_file).convert('RGB')
    
    if st.button("é–‹å§‹æ·±åº¦æª¢æ¸¬"):
        face = mtcnn(img)

        if face is None:
            st.error("âŒ æœªåµæ¸¬åˆ°äººè‡‰ï¼ŒDeepfake åˆ†æéœ€åŒ…å«æ¸…æ¥šäººè‡‰ã€‚")
            st.info("ğŸ‘‰ å»ºè­°ï¼šæ­£é¢ã€å–®äººã€è‡‰éƒ¨ä½”ç•«é¢ 30% ä»¥ä¸Š")
            st.stop()

        # ç¢ºä¿ MTCNN è¼¸å‡ºçš„ Tensor åœ¨åˆç†ç¯„åœ
        face = torch.clamp(face, 0, 1)
        
        # 1. æº–å‚™ç©ºåŸŸ Tensor (éœ€è¦ Normalize)
        normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        rgb_tensor = normalize(face).to(device)
        
        # 2. æº–å‚™é »åŸŸ Tensor
        face_pil = transforms.ToPILImage()(face)
        fft_tensor = process_fft(face_pil).to(device)
        
        # 3. åˆä½µç‚º 4 é€šé“ [Batch, 4, 224, 224]
        input_tensor = torch.cat((rgb_tensor, fft_tensor), dim=0).unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(input_tensor)
            prob = torch.softmax(output, dim=1)[0]
        
        # --- UI é¡¯ç¤º ---
        col1, col2, col3 = st.columns(3)
        with col1:
            st.image(img, caption="åŸå§‹åœ–", use_container_width=True)
        with col2:
            # é¡¯ç¤º FFT é »è­œåœ–
            fft_viz = fft_tensor.squeeze().cpu().numpy()
            # åŠ å…¥ clamp=True æ˜¯é‡å° Streamlit çš„é›™é‡ä¿éšª
            st.image(fft_viz, caption="FFT é »è­œ (AI å½å½±åµæ¸¬)", clamp=True, use_container_width=True)
        with col3:
            fake_prob = prob[0].item()
            real_prob = prob[1].item()

            st.metric("ğŸŸ¥ å½é€ æ©Ÿç‡", f"{fake_prob*100:.2f}%")
            st.metric("ğŸŸ© çœŸå¯¦æ©Ÿç‡", f"{real_prob*100:.2f}%")

            if fake_prob > real_prob:
                st.error("ğŸš¨ åˆ¤å®šç‚º AI ç”Ÿæˆ (Deepfake)")
            else:
                st.success("âœ… åˆ¤å®šç‚ºçœŸå¯¦äººè‡‰")